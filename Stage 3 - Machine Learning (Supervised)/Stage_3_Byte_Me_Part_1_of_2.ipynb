{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_7Z37EMFGPf"
      },
      "source": [
        "## STEP 3 Part 1 of 2 - FINAL PROJECT\n",
        "### Part 1: Find best model\n",
        "### Rakamin - Data Science Batch 47\n",
        "## Group 3 <br>\n",
        "# **Byte Me** <br>\n",
        "Hijir Della Wirasti <br>\n",
        "Mauliddinia Iftikhar Agnany <br>\n",
        "Jericho Medion Haryono <br>\n",
        "Fakhri Dwi Nugroho <br>\n",
        "Ryan Nofandi <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rngodjmFl3b"
      },
      "source": [
        "Laporan: https://docs.google.com/document/d/1FLA2xAlc_K8GkiqfJ7efhuxjzPcuUDJpxs5HS1Bn9i8/edit?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fckOLNqMFytM"
      },
      "source": [
        "Dataset awal: Home Credit Default Risk<br>\n",
        "https://www.kaggle.com/competitions/home-credit-default-risk/data <br>\n",
        "\n",
        "Dataset setelah Pre-processing<br>\n",
        "https://drive.google.com/file/d/1cX9JxNyOKYMBXlVw2ewd3HxzwsbnGnbL/view?usp=sharing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ms5XRYJYXC5Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import warnings\n",
        "\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcMtsDfeXO4u"
      },
      "source": [
        "## Read the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MosBCudRXPpQ"
      },
      "outputs": [],
      "source": [
        "df_train_log = pd.read_csv('df_train_log.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-xBgMLPX6QY"
      },
      "source": [
        "# Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGllQZH3XphB",
        "outputId": "1df26035-3188-43c6-c270-db7086228b31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   NAME_CONTRACT_TYPE  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
            "0            0.324189     1.390300     -0.715531         0.665112   \n",
            "1            0.324189    -0.719269     -0.715531        -1.503506   \n",
            "2           -3.084622     1.390300      1.397564         0.665112   \n",
            "3            0.324189    -0.719269     -0.715531         0.665112   \n",
            "4            0.324189     1.390300     -0.715531         0.665112   \n",
            "\n",
            "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
            "0     -0.589199          0.633425   -0.215579     0.086951   \n",
            "1     -0.589199          1.222404    1.402158     0.761529   \n",
            "2     -0.589199         -1.615780   -1.756794    -2.289051   \n",
            "3     -0.589199         -0.196692   -0.582710     0.423738   \n",
            "4     -0.589199         -0.412398    0.109361    -0.136354   \n",
            "\n",
            "   REGION_POPULATION_RELATIVE  DAYS_BIRTH  ...  \\\n",
            "0                         0.0    1.509513  ...   \n",
            "1                         0.0   -0.158701  ...   \n",
            "2                         0.0   -0.679675  ...   \n",
            "3                         0.0   -0.670311  ...   \n",
            "4                         0.0   -0.882035  ...   \n",
            "\n",
            "   ORGANIZATION_TYPE_Trade: type 7  ORGANIZATION_TYPE_Transport: type 1  \\\n",
            "0                         -0.16166                            -0.025432   \n",
            "1                         -0.16166                            -0.025432   \n",
            "2                         -0.16166                            -0.025432   \n",
            "3                         -0.16166                            -0.025432   \n",
            "4                         -0.16166                            -0.025432   \n",
            "\n",
            "   ORGANIZATION_TYPE_Transport: type 2  ORGANIZATION_TYPE_Transport: type 3  \\\n",
            "0                            -0.084839                            -0.062102   \n",
            "1                            -0.084839                            -0.062102   \n",
            "2                            -0.084839                            -0.062102   \n",
            "3                            -0.084839                            -0.062102   \n",
            "4                            -0.084839                            -0.062102   \n",
            "\n",
            "   ORGANIZATION_TYPE_Transport: type 4  ORGANIZATION_TYPE_University  \\\n",
            "0                            -0.133695                     -0.065743   \n",
            "1                            -0.133695                     -0.065743   \n",
            "2                            -0.133695                     -0.065743   \n",
            "3                            -0.133695                     -0.065743   \n",
            "4                            -0.133695                     -0.065743   \n",
            "\n",
            "   NEW_DAYS_EMPLOYED_PERC  NEW_INCOME_CREDIT_PERC  NEW_ANNUITY_INCOME_PERC  \\\n",
            "0                0.454354                0.192998                -0.622996   \n",
            "1                0.454885               -0.374635                -0.514607   \n",
            "2                0.446010                0.196851                -0.855615   \n",
            "3                0.468268                0.062935                 0.413541   \n",
            "4                0.467142               -0.319488                -0.009214   \n",
            "\n",
            "   NEW_PAYMENT_RATE  \n",
            "0          0.314157  \n",
            "1         -1.160218  \n",
            "2         -0.163872  \n",
            "3          1.834859  \n",
            "4         -0.492021  \n",
            "\n",
            "[5 rows x 144 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Memisahkan fitur (X) dan target (y)\n",
        "X = df_train_log.drop(columns='TARGET')\n",
        "y = df_train_log['TARGET']\n",
        "\n",
        "# Inisialisasi StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Terapkan StandardScaler ke fitur\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Menampilkan beberapa baris pertama dari X_scaled\n",
        "print(pd.DataFrame(X_scaled, columns=X.columns).head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZDxStjhYCjC"
      },
      "source": [
        "# Handle Class Imbalance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gBvxoszYGa1"
      },
      "source": [
        "## Oversampling (SMOTE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf4AfrKcYDUc",
        "outputId": "3f3d7452-637a-484c-c7cf-430673f75e39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribusi kelas sebelum SMOTE: Counter({0: 278843, 1: 24396})\n",
            "Distribusi kelas setelah SMOTE: Counter({0: 278843, 1: 139421})\n",
            "   NAME_CONTRACT_TYPE  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
            "0            0.324189     1.390300     -0.715531         0.665112   \n",
            "1            0.324189    -0.719269     -0.715531        -1.503506   \n",
            "2           -3.084622     1.390300      1.397564         0.665112   \n",
            "3            0.324189    -0.719269     -0.715531         0.665112   \n",
            "4            0.324189     1.390300     -0.715531         0.665112   \n",
            "\n",
            "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
            "0     -0.589199          0.633425   -0.215579     0.086951   \n",
            "1     -0.589199          1.222404    1.402158     0.761529   \n",
            "2     -0.589199         -1.615780   -1.756794    -2.289051   \n",
            "3     -0.589199         -0.196692   -0.582710     0.423738   \n",
            "4     -0.589199         -0.412398    0.109361    -0.136354   \n",
            "\n",
            "   REGION_POPULATION_RELATIVE  DAYS_BIRTH  ...  \\\n",
            "0                         0.0    1.509513  ...   \n",
            "1                         0.0   -0.158701  ...   \n",
            "2                         0.0   -0.679675  ...   \n",
            "3                         0.0   -0.670311  ...   \n",
            "4                         0.0   -0.882035  ...   \n",
            "\n",
            "   ORGANIZATION_TYPE_Trade: type 7  ORGANIZATION_TYPE_Transport: type 1  \\\n",
            "0                         -0.16166                            -0.025432   \n",
            "1                         -0.16166                            -0.025432   \n",
            "2                         -0.16166                            -0.025432   \n",
            "3                         -0.16166                            -0.025432   \n",
            "4                         -0.16166                            -0.025432   \n",
            "\n",
            "   ORGANIZATION_TYPE_Transport: type 2  ORGANIZATION_TYPE_Transport: type 3  \\\n",
            "0                            -0.084839                            -0.062102   \n",
            "1                            -0.084839                            -0.062102   \n",
            "2                            -0.084839                            -0.062102   \n",
            "3                            -0.084839                            -0.062102   \n",
            "4                            -0.084839                            -0.062102   \n",
            "\n",
            "   ORGANIZATION_TYPE_Transport: type 4  ORGANIZATION_TYPE_University  \\\n",
            "0                            -0.133695                     -0.065743   \n",
            "1                            -0.133695                     -0.065743   \n",
            "2                            -0.133695                     -0.065743   \n",
            "3                            -0.133695                     -0.065743   \n",
            "4                            -0.133695                     -0.065743   \n",
            "\n",
            "   NEW_DAYS_EMPLOYED_PERC  NEW_INCOME_CREDIT_PERC  NEW_ANNUITY_INCOME_PERC  \\\n",
            "0                0.454354                0.192998                -0.622996   \n",
            "1                0.454885               -0.374635                -0.514607   \n",
            "2                0.446010                0.196851                -0.855615   \n",
            "3                0.468268                0.062935                 0.413541   \n",
            "4                0.467142               -0.319488                -0.009214   \n",
            "\n",
            "   NEW_PAYMENT_RATE  \n",
            "0          0.314157  \n",
            "1         -1.160218  \n",
            "2         -0.163872  \n",
            "3          1.834859  \n",
            "4         -0.492021  \n",
            "\n",
            "[5 rows x 144 columns]\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# Inisialisasi SMOTE\n",
        "smote = SMOTE(sampling_strategy=0.5)  # Menambah kelas minoritas hingga mencapai 50% dari kelas mayoritas\n",
        "\n",
        "# Terapkan SMOTE ke data yang sudah discaling\n",
        "X_smote, y_smote = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Print distribusi kelas setelah SMOTE\n",
        "print(f'Distribusi kelas sebelum SMOTE: {Counter(y)}')\n",
        "print(f'Distribusi kelas setelah SMOTE: {Counter(y_smote)}')\n",
        "\n",
        "# Optional: Tampilkan beberapa baris data hasil resampling\n",
        "print(pd.DataFrame(X_smote, columns=X.columns).head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXqL0ziEYLI5"
      },
      "source": [
        "## Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTZfiPugYL0S",
        "outputId": "acfa20d4-aad0-45ba-c6a7-d73cfd917e8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribusi kelas sebelum undersampling: Counter({0: 278843, 1: 24396})\n",
            "Distribusi kelas setelah undersampling: Counter({0: 30495, 1: 24396})\n",
            "   NAME_CONTRACT_TYPE  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
            "0            0.324189     1.390300      1.397564         0.665112   \n",
            "1            0.324189    -0.719269     -0.715531        -1.503506   \n",
            "2            0.324189     1.390300      1.397564         0.665112   \n",
            "3            0.324189    -0.719269     -0.715531         0.665112   \n",
            "4            0.324189    -0.719269      1.397564         0.665112   \n",
            "\n",
            "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
            "0     -0.589199          1.222404    0.074070     0.675279   \n",
            "1     -0.589199         -0.926918   -1.122195    -0.619653   \n",
            "2      2.528457         -2.250760    0.492988    -0.822423   \n",
            "3     -0.589199          0.118904   -0.296762     0.741823   \n",
            "4     -0.589199         -1.359533   -1.713667    -1.103239   \n",
            "\n",
            "   REGION_POPULATION_RELATIVE  DAYS_BIRTH  ...  \\\n",
            "0                         0.0   -0.137688  ...   \n",
            "1                         0.0   -1.020672  ...   \n",
            "2                         0.0    0.123827  ...   \n",
            "3                         0.0    1.665736  ...   \n",
            "4                         0.0   -0.856911  ...   \n",
            "\n",
            "   ORGANIZATION_TYPE_Trade: type 7  ORGANIZATION_TYPE_Transport: type 1  \\\n",
            "0                         -0.16166                            -0.025432   \n",
            "1                         -0.16166                            -0.025432   \n",
            "2                         -0.16166                            -0.025432   \n",
            "3                         -0.16166                            -0.025432   \n",
            "4                         -0.16166                            -0.025432   \n",
            "\n",
            "   ORGANIZATION_TYPE_Transport: type 2  ORGANIZATION_TYPE_Transport: type 3  \\\n",
            "0                            -0.084839                            -0.062102   \n",
            "1                            -0.084839                            -0.062102   \n",
            "2                            -0.084839                            -0.062102   \n",
            "3                            -0.084839                            -0.062102   \n",
            "4                            -0.084839                            -0.062102   \n",
            "\n",
            "   ORGANIZATION_TYPE_Transport: type 4  ORGANIZATION_TYPE_University  \\\n",
            "0                            -0.133695                     -0.065743   \n",
            "1                            -0.133695                     -0.065743   \n",
            "2                            -0.133695                     -0.065743   \n",
            "3                            -0.133695                     -0.065743   \n",
            "4                            -0.133695                     -0.065743   \n",
            "\n",
            "   NEW_DAYS_EMPLOYED_PERC  NEW_INCOME_CREDIT_PERC  NEW_ANNUITY_INCOME_PERC  \\\n",
            "0                0.455403                0.274887                -0.578982   \n",
            "1               -2.228512                0.088088                -0.032974   \n",
            "2               -3.091027               -0.640307                 1.300823   \n",
            "3                0.471068                0.021291                 0.459401   \n",
            "4               -2.325191                0.293877                -0.129578   \n",
            "\n",
            "   NEW_PAYMENT_RATE  \n",
            "0          0.640392  \n",
            "1          1.126190  \n",
            "2         -1.397067  \n",
            "3          1.706382  \n",
            "4          1.732164  \n",
            "\n",
            "[5 rows x 144 columns]\n"
          ]
        }
      ],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "\n",
        "# Inisialisasi RandomUnderSampler\n",
        "undersample = RandomUnderSampler(sampling_strategy=0.8)  # Mengurangi jumlah kelas mayoritas hingga mencapai 80% dari jumlah kelas minoritas\n",
        "\n",
        "# Terapkan RandomUnderSampler ke data yang sudah discaling\n",
        "X_under, y_under = undersample.fit_resample(X_scaled, y)\n",
        "\n",
        "# Print distribusi kelas setelah undersampling\n",
        "print(f'Distribusi kelas sebelum undersampling: {Counter(y)}')\n",
        "print(f'Distribusi kelas setelah undersampling: {Counter(y_under)}')\n",
        "\n",
        "# Optional: Tampilkan beberapa baris data hasil resampling\n",
        "print(pd.DataFrame(X_under, columns=X.columns).head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoRViHuAYQlu"
      },
      "source": [
        "# Test Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_YGElkUYUFo"
      },
      "source": [
        "## Model Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKX0KtHzwHLv"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, make_scorer, fbeta_score\n",
        "import pandas as pd\n",
        "\n",
        "# Define function to train model and calculate metrics\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Metrics calculation\n",
        "    metrics = {\n",
        "        \"Accuracy (Train Set)\": accuracy_score(y_train, y_train_pred),\n",
        "        \"Accuracy (Test Set)\": accuracy_score(y_test, y_test_pred),\n",
        "        \"Precision (Test Set)\": precision_score(y_test, y_test_pred),\n",
        "        \"Recall (Test Set)\": recall_score(y_test, y_test_pred),\n",
        "        \"F1-Score (Test Set)\": f1_score(y_test, y_test_pred),\n",
        "        \"F2-Score (Test Set)\": fbeta_score(y_test, y_test_pred, beta=2),\n",
        "    }\n",
        "\n",
        "    # Calculate ROC AUC if the model supports predict_proba\n",
        "    try:\n",
        "        metrics[\"ROC AUC (Train Set)\"] = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])\n",
        "        metrics[\"ROC AUC (Test Set)\"] = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "    except AttributeError:\n",
        "        metrics[\"ROC AUC (Train Set)\"] = None\n",
        "        metrics[\"ROC AUC (Test Set)\"] = None\n",
        "\n",
        "    # Cross-validation recall score\n",
        "    metrics[\"Recall (Cross-Validation Train)\"] = cross_val_score(model, X_train, y_train, cv=5, scoring=make_scorer(recall_score)).mean()\n",
        "    metrics[\"Recall (Cross-Validation Test)\"] = cross_val_score(model, X_test, y_test, cv=5, scoring=make_scorer(recall_score)).mean()\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Splitting the data\n",
        "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_smote, y_smote, test_size=0.3, random_state=42)\n",
        "X_train_under, X_test_under, y_train_under, y_test_under = train_test_split(X_under, y_under, test_size=0.3, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8G19IkZYdHE"
      },
      "source": [
        "## 1. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r7zsEEQ4g4w",
        "outputId": "be29ab0b-ba07-48e7-ceb7-9c124b0cf64d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Original Data:\n",
            "Accuracy (Train Set): 0.9194\n",
            "Accuracy (Test Set): 0.9200\n",
            "Precision (Test Set): 0.5000\n",
            "Recall (Test Set): 0.0001\n",
            "F1-Score (Test Set): 0.0003\n",
            "F2-Score (Test Set): 0.0002\n",
            "ROC AUC (Train Set): 0.6770\n",
            "ROC AUC (Test Set): 0.6799\n",
            "Recall (Cross-Validation Train): 0.0002\n",
            "Recall (Cross-Validation Test): 0.0001\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize the Logistic Regression model (commonly used for classification tasks)\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Evaluate the model using original data\n",
        "metrics_orig = evaluate_model(model, X_train_orig, X_test_orig, y_train_orig, y_test_orig)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Original Data:\")\n",
        "for metric, value in metrics_orig.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OctwUXBZcKY8"
      },
      "source": [
        "### Hyperparameter Tuning Logistic Regression <br>\n",
        "Original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNF7aCLucTOA",
        "outputId": "8d1b6cd6-6bae-4f08-94e2-2edced827ae1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "Best Parameters for Logistic Regression: {'C': 0.1, 'max_iter': 100, 'solver': 'liblinear'}\n",
            "Best Cross-Validation Accuracy: 0.9193657044585297\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
        "    'solver': ['liblinear', 'lbfgs'],  # Different solvers\n",
        "    'max_iter': [100, 200, 500]  # Maximum number of iterations\n",
        "}\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "log_reg = LogisticRegression(random_state=42)\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid,\n",
        "                           scoring='accuracy', cv=5, n_jobs=-1, verbose=1)\n",
        "\n",
        "# Perform the grid search on the training data\n",
        "grid_search.fit(X_train_orig, y_train_orig)\n",
        "\n",
        "# Retrieve the best model and parameters\n",
        "best_log_reg = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Print the best parameters and the corresponding accuracy\n",
        "print(\"Best Parameters for Logistic Regression:\", best_params)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt-J81YtpS3d",
        "outputId": "f83f9c19-37d9-4b81-ca8d-32bd8fd658fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Original Data:\n",
            "Accuracy (Train Set): 0.9194\n",
            "Accuracy (Test Set): 0.9200\n",
            "Precision (Test Set): 0.5000\n",
            "Recall (Test Set): 0.0001\n",
            "F1-Score (Test Set): 0.0003\n",
            "F2-Score (Test Set): 0.0002\n",
            "ROC AUC (Train Set): 0.6776\n",
            "ROC AUC (Test Set): 0.6805\n",
            "Recall (Cross-Validation Train): 0.0002\n",
            "Recall (Cross-Validation Test): 0.0001\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize the Logistic Regression model with the best parameters\n",
        "model = LogisticRegression(C=0.1, max_iter=100, solver='liblinear')\n",
        "\n",
        "# Evaluate the model using original data\n",
        "metrics_orig = evaluate_model(model, X_train_orig, X_test_orig, y_train_orig, y_test_orig)\n",
        "\n",
        "# Display the metrics\n",
        "\n",
        "print(\"Evaluation Metrics on Original Data:\")\n",
        "for metric, value in metrics_orig.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6MjIfTUgNCz"
      },
      "source": [
        "### 1a. Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbZUzxWnpmdL",
        "outputId": "279598a3-bd81-4b30-81aa-b65f2825bb70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Oversampled Data:\n",
            "Accuracy (Train Set): 0.6935\n",
            "Accuracy (Test Set): 0.6922\n",
            "Precision (Test Set): 0.5775\n",
            "Recall (Test Set): 0.2894\n",
            "F1-Score (Test Set): 0.3856\n",
            "F2-Score (Test Set): 0.3215\n",
            "ROC AUC (Train Set): 0.7071\n",
            "ROC AUC (Test Set): 0.7042\n",
            "Recall (Cross-Validation Train): 0.2908\n",
            "Recall (Cross-Validation Test): 0.2874\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using oversampled data\n",
        "metrics_over = evaluate_model(model, X_train_over, X_test_over, y_train_over, y_test_over)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Oversampled Data:\")\n",
        "for metric, value in metrics_over.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o53CKiVpgROT"
      },
      "source": [
        "### 1b. Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N87TYPULrJgV",
        "outputId": "5d8293f4-4660-403d-ff55-2f8bdd57d66e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Undersampled Data with Logistic Regression:\n",
            "Accuracy (Train Set): 0.6405\n",
            "Accuracy (Test Set): 0.6391\n",
            "Precision (Test Set): 0.6157\n",
            "Recall (Test Set): 0.5093\n",
            "F1-Score (Test Set): 0.5575\n",
            "F2-Score (Test Set): 0.5275\n",
            "ROC AUC (Train Set): 0.6843\n",
            "ROC AUC (Test Set): 0.6762\n",
            "Recall (Cross-Validation Train): 0.5005\n",
            "Recall (Cross-Validation Test): 0.5008\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize the Logistic Regression model with chosen parameters for undersampling evaluation\n",
        "model_lr = LogisticRegression(solver='liblinear', random_state=42)\n",
        "\n",
        "# Evaluate the Logistic Regression model using undersampled data\n",
        "metrics_lr_under = evaluate_model(model_lr, X_train_under, X_test_under, y_train_under, y_test_under)\n",
        "\n",
        "# Display the metrics for the undersampled data\n",
        "print(\"Evaluation Metrics on Undersampled Data with Logistic Regression:\")\n",
        "for metric, value in metrics_lr_under.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fUit2Fpavg1"
      },
      "source": [
        "## 2. kNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1WiCAgSdBDA",
        "outputId": "e5cbbbdb-5037-4b3f-fad5-f6076eef68a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Original Data with kNN:\n",
            "Accuracy (Train Set): 1.0000\n",
            "Accuracy (Test Set): 0.9146\n",
            "Precision (Test Set): 0.1484\n",
            "Recall (Test Set): 0.0142\n",
            "F1-Score (Test Set): 0.0258\n",
            "F2-Score (Test Set): 0.0173\n",
            "ROC AUC (Train Set): 1.0000\n",
            "ROC AUC (Test Set): 0.5435\n",
            "Recall (Cross-Validation Train): 0.0147\n",
            "Recall (Cross-Validation Test): 0.0148\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Initialize the kNN model with chosen parameters\n",
        "model_knn = KNeighborsClassifier(n_neighbors=5, weights='distance', p=2)\n",
        "\n",
        "# Evaluate the kNN model using original data\n",
        "metrics_knn_orig = evaluate_model(model_knn, X_train_orig, X_test_orig, y_train_orig, y_test_orig)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Original Data with kNN:\")\n",
        "for metric, value in metrics_knn_orig.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48DVH15LAxyw"
      },
      "source": [
        "### Hyperparameter kNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-wdYRIAA2Ev",
        "outputId": "a910beea-e745-4bde-88d1-1ee35be2a5c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "Best Parameters for kNN: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
            "Evaluation Metrics on Original Data with Best kNN Model:\n",
            "Accuracy (Train Set): 1.0000\n",
            "Accuracy (Test Set): 0.9033\n",
            "Precision (Test Set): 0.1213\n",
            "Recall (Test Set): 0.0335\n",
            "F1-Score (Test Set): 0.0525\n",
            "F2-Score (Test Set): 0.0392\n",
            "ROC AUC (Train Set): 1.0000\n",
            "ROC AUC (Test Set): 0.5334\n",
            "Recall (Cross-Validation Train): 0.0386\n",
            "Recall (Cross-Validation Test): 0.0393\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid for kNN\n",
        "param_grid_knn = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
        "}\n",
        "\n",
        "# Initialize kNN model\n",
        "model_knn = KNeighborsClassifier()\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search_knn = GridSearchCV(estimator=model_knn, param_grid=param_grid_knn, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
        "\n",
        "# Fit the grid search to find the best parameters\n",
        "grid_search_knn.fit(X_train_orig, y_train_orig)\n",
        "\n",
        "# Get the best model with the best parameters\n",
        "best_knn_model = grid_search_knn.best_estimator_\n",
        "print(\"Best Parameters for kNN:\", grid_search_knn.best_params_)\n",
        "\n",
        "# Evaluate the best model using the original data\n",
        "metrics_knn_best = evaluate_model(best_knn_model, X_train_orig, X_test_orig, y_train_orig, y_test_orig)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Original Data with Best kNN Model:\")\n",
        "for metric, value in metrics_knn_best.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45l9zA9UgtVe"
      },
      "source": [
        "### 2a. Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cNOVsDFrlJU",
        "outputId": "bd53174c-c4ab-45ae-bf53-bf8f7e98483e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Oversampled Data with kNN:\n",
            "Accuracy (Train Set): 1.0000\n",
            "Accuracy (Test Set): 0.7757\n",
            "Precision (Test Set): 0.5996\n",
            "Recall (Test Set): 0.9870\n",
            "F1-Score (Test Set): 0.7460\n",
            "F2-Score (Test Set): 0.8741\n",
            "ROC AUC (Train Set): 1.0000\n",
            "ROC AUC (Test Set): 0.9445\n",
            "Recall (Cross-Validation Train): 0.9755\n",
            "Recall (Cross-Validation Test): 0.8955\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Initialize the kNN model with chosen parameters for oversampling evaluation\n",
        "model_knn = KNeighborsClassifier(n_neighbors=5, weights='distance', p=2)\n",
        "\n",
        "# Evaluate the kNN model using oversampled data\n",
        "metrics_knn_over = evaluate_model(model_knn, X_train_over, X_test_over, y_train_over, y_test_over)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Oversampled Data with kNN:\")\n",
        "for metric, value in metrics_knn_over.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaScc87Cgv_d"
      },
      "source": [
        "### 2b. Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8t0KTZStr98K",
        "outputId": "2fe0f22f-6137-42d7-b435-e6b439caab69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Undersampled Data with kNN:\n",
            "Accuracy (Train Set): 1.0000\n",
            "Accuracy (Test Set): 0.5556\n",
            "Precision (Test Set): 0.5023\n",
            "Recall (Test Set): 0.4721\n",
            "F1-Score (Test Set): 0.4867\n",
            "F2-Score (Test Set): 0.4779\n",
            "ROC AUC (Train Set): 1.0000\n",
            "ROC AUC (Test Set): 0.5640\n",
            "Recall (Cross-Validation Train): 0.4808\n",
            "Recall (Cross-Validation Test): 0.4737\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Initialize the kNN model with chosen parameters for undersampling evaluation\n",
        "model_knn = KNeighborsClassifier(n_neighbors=5, weights='distance', p=2)\n",
        "\n",
        "# Evaluate the kNN model using undersampled data\n",
        "metrics_knn_under = evaluate_model(model_knn, X_train_under, X_test_under, y_train_under, y_test_under)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Undersampled Data with kNN:\")\n",
        "for metric, value in metrics_knn_under.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMvjyUiCa74H"
      },
      "source": [
        "## 3. Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HTKj2LedKhu",
        "outputId": "3629282a-48b6-48ff-c592-5627481e57ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Original Data with Decision Tree:\n",
            "Accuracy (Train Set): 1.0000\n",
            "Accuracy (Test Set): 0.8471\n",
            "Precision (Test Set): 0.1133\n",
            "Recall (Test Set): 0.1336\n",
            "F1-Score (Test Set): 0.1226\n",
            "F2-Score (Test Set): 0.1290\n",
            "ROC AUC (Train Set): 1.0000\n",
            "ROC AUC (Test Set): 0.5214\n",
            "Recall (Cross-Validation Train): 0.1261\n",
            "Recall (Cross-Validation Test): 0.1399\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize the Decision Tree model with chosen parameters (you can adjust max_depth, criterion, etc. if needed)\n",
        "model_tree = DecisionTreeClassifier()\n",
        "\n",
        "# Evaluate the Decision Tree model using original data\n",
        "metrics_tree_orig = evaluate_model(model_tree, X_train_orig, X_test_orig, y_train_orig, y_test_orig)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Original Data with Decision Tree:\")\n",
        "for metric, value in metrics_tree_orig.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjQnVuTHsDFA"
      },
      "source": [
        "#### Hyperparameter Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jepZm9ZpAonZ",
        "outputId": "b638679b-25b9-461e-d6ee-92b655ea605a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
            "Best Parameters for Decision Tree: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "Evaluation Metrics on Original Data with Best Decision Tree Model:\n",
            "Accuracy (Train Set): 0.9998\n",
            "Accuracy (Test Set): 0.8535\n",
            "Precision (Test Set): 0.1210\n",
            "Recall (Test Set): 0.1327\n",
            "F1-Score (Test Set): 0.1266\n",
            "F2-Score (Test Set): 0.1302\n",
            "ROC AUC (Train Set): 1.0000\n",
            "ROC AUC (Test Set): 0.5242\n",
            "Recall (Cross-Validation Train): 0.1304\n",
            "Recall (Cross-Validation Test): 0.1340\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 5, 10, 20],\n",
        "    'min_samples_leaf': [1, 2, 5, 10],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Initialize Decision Tree model\n",
        "model_tree = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=model_tree, param_grid=param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
        "\n",
        "# Fit the grid search to find the best parameters\n",
        "grid_search.fit(X_train_orig, y_train_orig)\n",
        "\n",
        "# Get the best model with the best parameters\n",
        "best_tree_model = grid_search.best_estimator_\n",
        "print(\"Best Parameters for Decision Tree:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate the best model using the original data\n",
        "metrics_tree_best = evaluate_model(best_tree_model, X_train_orig, X_test_orig, y_train_orig, y_test_orig)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Original Data with Best Decision Tree Model:\")\n",
        "for metric, value in metrics_tree_best.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H91iGav8sLs3"
      },
      "source": [
        "### 3a. Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERa5v8WYsV7j",
        "outputId": "097dd83f-9b13-4fd1-da75-1f5eb9bc60c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Oversampled Data with Decision Tree:\n",
            "Accuracy (Train Set): 1.0000\n",
            "Accuracy (Test Set): 0.8761\n",
            "Precision (Test Set): 0.8060\n",
            "Recall (Test Set): 0.8281\n",
            "F1-Score (Test Set): 0.8169\n",
            "F2-Score (Test Set): 0.8236\n",
            "ROC AUC (Train Set): 1.0000\n",
            "ROC AUC (Test Set): 0.8641\n",
            "Recall (Cross-Validation Train): 0.8250\n",
            "Recall (Cross-Validation Test): 0.7995\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Define the Decision Tree model\n",
        "model_tree = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the model to the oversampled training data\n",
        "model_tree.fit(X_train_over, y_train_over)\n",
        "\n",
        "# Evaluate the model\n",
        "metrics_tree_over = evaluate_model(model_tree, X_train_over, X_test_over, y_train_over, y_test_over)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Oversampled Data with Decision Tree:\")\n",
        "for metric, value in metrics_tree_over.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3esHJzSsSOd"
      },
      "source": [
        "### 3b. Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-b8FPkZFtHlm",
        "outputId": "b9ca39d8-b2b8-4642-b627-f7e7d96ad618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Undersampled Data with Decision Tree:\n",
            "Accuracy (Train Set): 1.0000\n",
            "Accuracy (Test Set): 0.5533\n",
            "Precision (Test Set): 0.4996\n",
            "Recall (Test Set): 0.5023\n",
            "F1-Score (Test Set): 0.5009\n",
            "F2-Score (Test Set): 0.5018\n",
            "ROC AUC (Train Set): 1.0000\n",
            "ROC AUC (Test Set): 0.5484\n",
            "Recall (Cross-Validation Train): 0.4945\n",
            "Recall (Cross-Validation Test): 0.5184\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Define the Decision Tree model\n",
        "model_tree = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the model to the undersampled training data\n",
        "model_tree.fit(X_train_under, y_train_under)\n",
        "\n",
        "# Evaluate the model\n",
        "metrics_tree_under = evaluate_model(model_tree, X_train_under, X_test_under, y_train_under, y_test_under)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Undersampled Data with Decision Tree:\")\n",
        "for metric, value in metrics_tree_under.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW7UcsopbAps"
      },
      "source": [
        "## 4. Bagging: Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2JojZrCddSc",
        "outputId": "d3627809-a378-4234-9916-8658cf4602fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Original Data with Random Forest:\n",
            "Accuracy (Train Set): 1.0000\n",
            "Accuracy (Test Set): 0.9200\n",
            "Precision (Test Set): 1.0000\n",
            "Recall (Test Set): 0.0001\n",
            "F1-Score (Test Set): 0.0003\n",
            "F2-Score (Test Set): 0.0002\n",
            "ROC AUC (Train Set): 1.0000\n",
            "ROC AUC (Test Set): 0.6544\n",
            "Recall (Cross-Validation Train): 0.0002\n",
            "Recall (Cross-Validation Test): 0.0000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest model with chosen parameters (you can adjust n_estimators, max_depth, etc.)\n",
        "model_rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Evaluate the Random Forest model using original data\n",
        "metrics_rf_orig = evaluate_model(model_rf, X_train_orig, X_test_orig, y_train_orig, y_test_orig)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Original Data with Random Forest:\")\n",
        "for metric, value in metrics_rf_orig.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_us0hh5A-kE"
      },
      "source": [
        "### Hyperparameter Bagging: Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7_xP7_xBDzi",
        "outputId": "4a7dd483-bdf9-4e98-cb23-26a405f7b7d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n",
            "Best Parameters for Random Forest: {'criterion': 'gini', 'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Evaluation Metrics on Original Data with Best Random Forest Model:\n",
            "Accuracy (Train Set): 0.9998\n",
            "Accuracy (Test Set): 0.9200\n",
            "Precision (Test Set): 0.0000\n",
            "Recall (Test Set): 0.0000\n",
            "F1-Score (Test Set): 0.0000\n",
            "F2-Score (Test Set): 0.0000\n",
            "ROC AUC (Train Set): 1.0000\n",
            "ROC AUC (Test Set): 0.6564\n",
            "Recall (Cross-Validation Train): 0.0003\n",
            "Recall (Cross-Validation Test): 0.0000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid for Random Forest\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30, 40],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Initialize Random Forest model\n",
        "model_rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search_rf = GridSearchCV(estimator=model_rf, param_grid=param_grid_rf, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
        "\n",
        "# Fit the grid search to find the best parameters\n",
        "grid_search_rf.fit(X_train_orig, y_train_orig)\n",
        "\n",
        "# Get the best model with the best parameters\n",
        "best_rf_model = grid_search_rf.best_estimator_\n",
        "print(\"Best Parameters for Random Forest:\", grid_search_rf.best_params_)\n",
        "\n",
        "# Evaluate the best model using the original data\n",
        "metrics_rf_best = evaluate_model(best_rf_model, X_train_orig, X_test_orig, y_train_orig, y_test_orig)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Original Data with Best Random Forest Model:\")\n",
        "for metric, value in metrics_rf_best.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhx8lWoDtWqS"
      },
      "source": [
        "### 4a. Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1BER3AHtc86",
        "outputId": "7df2c61c-ac7f-46e3-c133-fd55f16d0748"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Oversampled Data with Random Forest:\n",
            "Accuracy (Train Set): 1.0000\n",
            "Accuracy (Test Set): 0.9370\n",
            "Precision (Test Set): 0.9996\n",
            "Recall (Test Set): 0.8117\n",
            "F1-Score (Test Set): 0.8959\n",
            "F2-Score (Test Set): 0.8434\n",
            "ROC AUC (Train Set): 1.0000\n",
            "ROC AUC (Test Set): 0.9655\n",
            "Recall (Cross-Validation Train): 0.8076\n",
            "Recall (Cross-Validation Test): 0.7778\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define the Random Forest model\n",
        "model_rf = RandomForestClassifier()\n",
        "\n",
        "# Fit the model to the oversampled training data\n",
        "model_rf.fit(X_train_over, y_train_over)\n",
        "\n",
        "# Evaluate the model\n",
        "metrics_rf_over = evaluate_model(model_rf, X_train_over, X_test_over, y_train_over, y_test_over)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Oversampled Data with Random Forest:\")\n",
        "for metric, value in metrics_rf_over.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoV71ChdtZzl"
      },
      "source": [
        "### 4b. Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_H8qzKXtqA6",
        "outputId": "816f8fea-1576-4bce-d485-f7685c3e5bb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Undersampled Data with Random Forest:\n",
            "Accuracy (Train Set): 1.0000\n",
            "Accuracy (Test Set): 0.6364\n",
            "Precision (Test Set): 0.6254\n",
            "Recall (Test Set): 0.4622\n",
            "F1-Score (Test Set): 0.5315\n",
            "F2-Score (Test Set): 0.4876\n",
            "ROC AUC (Train Set): 1.0000\n",
            "ROC AUC (Test Set): 0.6717\n",
            "Recall (Cross-Validation Train): 0.4554\n",
            "Recall (Cross-Validation Test): 0.4522\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define the Random Forest model\n",
        "model_rf = RandomForestClassifier()\n",
        "\n",
        "# Fit the model to the undersampled training data\n",
        "model_rf.fit(X_train_under, y_train_under)\n",
        "\n",
        "# Evaluate the model\n",
        "metrics_rf_under = evaluate_model(model_rf, X_train_under, X_test_under, y_train_under, y_test_under)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Undersampled Data with Random Forest:\")\n",
        "for metric, value in metrics_rf_under.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7TwyS_bbMjy"
      },
      "source": [
        "## 5. Boosting: Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFaH0N8Ldg5o",
        "outputId": "63b33ed7-e453-441d-9af9-2716109029b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Original Data with AdaBoost:\n",
            "Accuracy (Train Set): 0.9194\n",
            "Accuracy (Test Set): 0.9200\n",
            "Precision (Test Set): 1.0000\n",
            "Recall (Test Set): 0.0001\n",
            "F1-Score (Test Set): 0.0003\n",
            "F2-Score (Test Set): 0.0002\n",
            "ROC AUC (Train Set): 0.6910\n",
            "ROC AUC (Test Set): 0.6933\n",
            "Recall (Cross-Validation Train): 0.0002\n",
            "Recall (Cross-Validation Test): 0.0001\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Initialize the AdaBoost model with chosen parameters (you can adjust n_estimators, learning_rate, etc.)\n",
        "model_ab = AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=42)\n",
        "\n",
        "# Evaluate the AdaBoost model using original data\n",
        "metrics_ab_orig = evaluate_model(model_ab, X_train_orig, X_test_orig, y_train_orig, y_test_orig)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Original Data with AdaBoost:\")\n",
        "for metric, value in metrics_ab_orig.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp2vm9I1BHeY"
      },
      "source": [
        "### Hyperparameter Boosting: Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03XmEk9vBGWO",
        "outputId": "eb401ad7-937b-43fe-b702-2d41fedbde62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "Best Parameters for AdaBoost: {'estimator': DecisionTreeClassifier(max_depth=2), 'learning_rate': 1.5, 'n_estimators': 150}\n",
            "Evaluation Metrics on Original Data with Best AdaBoost Model:\n",
            "Accuracy (Train Set): 0.9189\n",
            "Accuracy (Test Set): 0.9190\n",
            "Precision (Test Set): 0.3168\n",
            "Recall (Test Set): 0.0114\n",
            "F1-Score (Test Set): 0.0220\n",
            "F2-Score (Test Set): 0.0141\n",
            "ROC AUC (Train Set): 0.7329\n",
            "ROC AUC (Test Set): 0.6969\n",
            "Recall (Cross-Validation Train): 0.0134\n",
            "Recall (Cross-Validation Test): 0.0242\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Define parameter grid for AdaBoost\n",
        "param_grid_ab = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.5, 1.0, 1.5],\n",
        "    'estimator': [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2)]\n",
        "}\n",
        "\n",
        "# Initialize AdaBoost model\n",
        "model_ab = AdaBoostClassifier(random_state=42)\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search_ab = GridSearchCV(estimator=model_ab, param_grid=param_grid_ab, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
        "\n",
        "# Fit the grid search to find the best parameters\n",
        "grid_search_ab.fit(X_train_orig, y_train_orig)\n",
        "\n",
        "# Get the best model with the best parameters\n",
        "best_ab_model = grid_search_ab.best_estimator_\n",
        "print(\"Best Parameters for AdaBoost:\", grid_search_ab.best_params_)\n",
        "\n",
        "# Evaluate the best model using the original data\n",
        "metrics_ab_best = evaluate_model(best_ab_model, X_train_orig, X_test_orig, y_train_orig, y_test_orig)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Original Data with Best AdaBoost Model:\")\n",
        "for metric, value in metrics_ab_best.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "326CYkMYu6D4"
      },
      "source": [
        "### 5a. Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GL7-z_86u9vz",
        "outputId": "b3276971-ab4c-46d3-9199-5a596bfcfe7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Oversampled Data with AdaBoost:\n",
            "Accuracy (Train Set): 0.8974\n",
            "Accuracy (Test Set): 0.8967\n",
            "Precision (Test Set): 0.9669\n",
            "Recall (Test Set): 0.7150\n",
            "F1-Score (Test Set): 0.8221\n",
            "F2-Score (Test Set): 0.7543\n",
            "ROC AUC (Train Set): 0.9214\n",
            "ROC AUC (Test Set): 0.9199\n",
            "Recall (Cross-Validation Train): 0.7144\n",
            "Recall (Cross-Validation Test): 0.7168\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Define the AdaBoost model\n",
        "model_ab = AdaBoostClassifier()\n",
        "\n",
        "# Fit the model to the oversampled training data\n",
        "model_ab.fit(X_train_over, y_train_over)\n",
        "\n",
        "# Evaluate the model\n",
        "metrics_ab_over = evaluate_model(model_ab, X_train_over, X_test_over, y_train_over, y_test_over)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Oversampled Data with AdaBoost:\")\n",
        "for metric, value in metrics_ab_over.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXWzFvmTu-u1"
      },
      "source": [
        "### 5b Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QN-zG7ugvUuH",
        "outputId": "d994bc01-2406-458b-f53a-63aec007068d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Undersampled Data with AdaBoost:\n",
            "Accuracy (Train Set): 0.6455\n",
            "Accuracy (Test Set): 0.6449\n",
            "Precision (Test Set): 0.6266\n",
            "Recall (Test Set): 0.5056\n",
            "F1-Score (Test Set): 0.5596\n",
            "F2-Score (Test Set): 0.5259\n",
            "ROC AUC (Train Set): 0.6916\n",
            "ROC AUC (Test Set): 0.6876\n",
            "Recall (Cross-Validation Train): 0.5118\n",
            "Recall (Cross-Validation Test): 0.5159\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Define the AdaBoost model\n",
        "model_ab = AdaBoostClassifier()\n",
        "\n",
        "# Fit the model to the undersampled training data\n",
        "model_ab.fit(X_train_under, y_train_under)\n",
        "\n",
        "# Evaluate the model\n",
        "metrics_ab_under = evaluate_model(model_ab, X_train_under, X_test_under, y_train_under, y_test_under)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Undersampled Data with AdaBoost:\")\n",
        "for metric, value in metrics_ab_under.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAto_qIkbRaQ"
      },
      "source": [
        "## 6. Boosting: XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjYtozUvNZB0",
        "outputId": "5a5186e4-421a-4f82-d1f5-5cc386533266"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.1.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: scipy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdRokhpneAKF",
        "outputId": "b8027a0a-2b61-4f83-d5e4-ad65d1e79aff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Original Data with XGBoost:\n",
            "Accuracy (Train Set): 0.9195\n",
            "Accuracy (Test Set): 0.9200\n",
            "Precision (Test Set): 0.5385\n",
            "Recall (Test Set): 0.0010\n",
            "F1-Score (Test Set): 0.0019\n",
            "F2-Score (Test Set): 0.0012\n",
            "ROC AUC (Train Set): 0.7726\n",
            "ROC AUC (Test Set): 0.7109\n",
            "Recall (Cross-Validation Train): 0.0006\n",
            "Recall (Cross-Validation Test): 0.0025\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "import pickle\n",
        "\n",
        "# Initialize the XGBoost model with chosen parameters (you can adjust n_estimators, learning_rate, max_depth, etc.)\n",
        "model_xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42, use_label_encoder=False, eval_metric=\"logloss\")\n",
        "\n",
        "# Evaluate the XGBoost model using original data\n",
        "metrics_xgb_orig = evaluate_model(model_xgb, X_train_orig, X_test_orig, y_train_orig, y_test_orig)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Original Data with XGBoost:\")\n",
        "for metric, value in metrics_xgb_orig.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xV-Dw0zdmr9f"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "model_name = \"xgb_model.pkl\"\n",
        "with open(model_name, \"wb\") as file:\n",
        "    pickle.dump(model_xgb, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmjn5SqHBfBR"
      },
      "source": [
        "### Hyperparameter Boosting: XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXLLY0o1Bj3f",
        "outputId": "7e43de98-dd3a-484b-f9e7-aed670e79d4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
            "Best Parameters for XGBoost: {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.6}\n",
            "Evaluation Metrics on Original Data with Best XGBoost Model:\n",
            "Accuracy (Train Set): 0.9251\n",
            "Accuracy (Test Set): 0.9192\n",
            "Precision (Test Set): 0.3590\n",
            "Recall (Test Set): 0.0135\n",
            "F1-Score (Test Set): 0.0260\n",
            "F2-Score (Test Set): 0.0167\n",
            "ROC AUC (Train Set): 0.9016\n",
            "ROC AUC (Test Set): 0.6893\n",
            "Recall (Cross-Validation Train): 0.0138\n",
            "Recall (Cross-Validation Test): 0.0197\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid for XGBoost\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [100, 150, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 6, 7],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize XGBoost model\n",
        "model_xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search_xgb = GridSearchCV(estimator=model_xgb, param_grid=param_grid_xgb, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
        "\n",
        "# Fit the grid search to find the best parameters\n",
        "grid_search_xgb.fit(X_train_orig, y_train_orig)\n",
        "\n",
        "# Get the best model with the best parameters\n",
        "best_xgb_model = grid_search_xgb.best_estimator_\n",
        "print(\"Best Parameters for XGBoost:\", grid_search_xgb.best_params_)\n",
        "\n",
        "# Evaluate the best model using the original data\n",
        "metrics_xgb_best = evaluate_model(best_xgb_model, X_train_orig, X_test_orig, y_train_orig, y_test_orig)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Original Data with Best XGBoost Model:\")\n",
        "for metric, value in metrics_xgb_best.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9tkXLkb8XyA"
      },
      "source": [
        "### 6a. Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euvE3FxB8gVi",
        "outputId": "f03630e8-d55b-46f6-949a-c780b2a924c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Oversampled Data with XGBoost:\n",
            "Accuracy (Train Set): 0.9406\n",
            "Accuracy (Test Set): 0.9387\n",
            "Precision (Test Set): 0.9985\n",
            "Recall (Test Set): 0.8176\n",
            "F1-Score (Test Set): 0.8990\n",
            "F2-Score (Test Set): 0.8483\n",
            "ROC AUC (Train Set): 0.9646\n",
            "ROC AUC (Test Set): 0.9469\n",
            "Recall (Cross-Validation Train): 0.8197\n",
            "Recall (Cross-Validation Test): 0.8165\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Define the XGBoost model\n",
        "model_xgb = xgb.XGBClassifier(device='cuda') #pake runtime T4 GPU\n",
        "\n",
        "# Fit the model to the oversampled training data\n",
        "model_xgb.fit(X_train_over, y_train_over)\n",
        "\n",
        "# Evaluate the model\n",
        "metrics_xgb_over = evaluate_model(model_xgb, X_train_over, X_test_over, y_train_over, y_test_over)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Oversampled Data with XGBoost:\")\n",
        "for metric, value in metrics_xgb_over.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQgRHpG-nIMz"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "model_name = \"xgb_model.pkl\"\n",
        "with open(model_name, \"wb\") as file:\n",
        "    pickle.dump(model_xgb, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJngwzcH1_tj"
      },
      "source": [
        "### Hyperparameter (Oversampling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Wp-ZTIg2IZK",
        "outputId": "907aa758-5739-4f4e-c952-5371a5b14830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
            "Best Parameters for XGBoost: {'colsample_bytree': 0.6, 'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 300, 'subsample': 1.0}\n",
            "Evaluation Metrics on Oversampled Data with Best XGBoost Model:\n",
            "Accuracy (Train Set): 0.9460\n",
            "Accuracy (Test Set): 0.9397\n",
            "Precision (Test Set): 0.9966\n",
            "Recall (Test Set): 0.8220\n",
            "F1-Score (Test Set): 0.9009\n",
            "F2-Score (Test Set): 0.8519\n",
            "ROC AUC (Train Set): 0.9861\n",
            "ROC AUC (Test Set): 0.9470\n",
            "Recall (Cross-Validation Train): 0.8239\n",
            "Recall (Cross-Validation Test): 0.8208\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Initialize XGBoost model\n",
        "model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', device='cuda')\n",
        "\n",
        "# Define parameter grid for hyperparameter tuning\n",
        "param_grid_xgb = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV for hyperparameter tuning using the oversampled training data\n",
        "grid_search_xgb = GridSearchCV(estimator=model_xgb, param_grid=param_grid_xgb, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
        "grid_search_xgb.fit(X_train_over, y_train_over)\n",
        "\n",
        "# Get the best model with the best parameters\n",
        "best_xgb_model = grid_search_xgb.best_estimator_\n",
        "print(\"Best Parameters for XGBoost:\", grid_search_xgb.best_params_)\n",
        "\n",
        "# Evaluate the best model using the oversampled test data\n",
        "metrics_xgb_over = evaluate_model(best_xgb_model, X_train_over, X_test_over, y_train_over, y_test_over)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Oversampled Data with Best XGBoost Model:\")\n",
        "for metric, value in metrics_xgb_over.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj5d7Tgv8cnr"
      },
      "source": [
        "### 6b. Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCyjZPeR8jgq",
        "outputId": "7e648c88-7b8e-407e-f924-246da2b288d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Undersampled Data with XGBoost:\n",
            "Accuracy (Train Set): 0.7960\n",
            "Accuracy (Test Set): 0.6431\n",
            "Precision (Test Set): 0.6150\n",
            "Recall (Test Set): 0.5361\n",
            "F1-Score (Test Set): 0.5728\n",
            "F2-Score (Test Set): 0.5502\n",
            "ROC AUC (Train Set): 0.8808\n",
            "ROC AUC (Test Set): 0.6898\n",
            "Recall (Cross-Validation Train): 0.5343\n",
            "Recall (Cross-Validation Test): 0.5348\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Define the XGBoost model\n",
        "model_xgb = xgb.XGBClassifier()\n",
        "\n",
        "# Fit the model to the undersampled training data\n",
        "model_xgb.fit(X_train_under, y_train_under)\n",
        "\n",
        "# Evaluate the model\n",
        "metrics_xgb_under = evaluate_model(model_xgb, X_train_under, X_test_under, y_train_under, y_test_under)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Undersampled Data with XGBoost:\")\n",
        "for metric, value in metrics_xgb_under.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k_VCxp8HQWX"
      },
      "source": [
        "#### Hyperparameter (Undersampling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhH4VN5KHVh5",
        "outputId": "b6e354b5-5f87-4755-c371-5b8cde12d21a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
            "Best Parameters for XGBoost: {'colsample_bytree': 0.6, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 300, 'subsample': 0.8}\n",
            "Evaluation Metrics on Undersampled Data with Best XGBoost Model:\n",
            "Accuracy (Train Set): 0.7004\n",
            "Accuracy (Test Set): 0.6578\n",
            "Precision (Test Set): 0.6385\n",
            "Recall (Test Set): 0.5378\n",
            "F1-Score (Test Set): 0.5839\n",
            "F2-Score (Test Set): 0.5553\n",
            "ROC AUC (Train Set): 0.7697\n",
            "ROC AUC (Test Set): 0.7112\n",
            "Recall (Cross-Validation Train): 0.5398\n",
            "Recall (Cross-Validation Test): 0.5412\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Initialize XGBoost model\n",
        "model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Define parameter grid for hyperparameter tuning\n",
        "param_grid_xgb = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV for hyperparameter tuning using the undersampled training data\n",
        "grid_search_xgb = GridSearchCV(estimator=model_xgb, param_grid=param_grid_xgb, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
        "grid_search_xgb.fit(X_train_under, y_train_under)\n",
        "\n",
        "# Get the best model with the best parameters\n",
        "best_xgb_model = grid_search_xgb.best_estimator_\n",
        "print(\"Best Parameters for XGBoost:\", grid_search_xgb.best_params_)\n",
        "\n",
        "# Evaluate the best model using the undersampled test data\n",
        "metrics_xgb_under = evaluate_model(best_xgb_model, X_train_under, X_test_under, y_train_under, y_test_under)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Undersampled Data with Best XGBoost Model:\")\n",
        "for metric, value in metrics_xgb_under.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgmQnCwobpkE"
      },
      "source": [
        "## 7. Stacking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zidxXDoEeEf_",
        "outputId": "cbc25995-1efb-4813-c5a5-c310904829e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Original Data with Stacking:\n",
            "Accuracy (Train Set): 0.9612\n",
            "Accuracy (Test Set): 0.9196\n",
            "Precision (Test Set): 0.3299\n",
            "Recall (Test Set): 0.0044\n",
            "F1-Score (Test Set): 0.0087\n",
            "F2-Score (Test Set): 0.0055\n",
            "ROC AUC (Train Set): 0.9998\n",
            "ROC AUC (Test Set): 0.6847\n",
            "Recall (Cross-Validation Train): 0.0066\n",
            "Recall (Cross-Validation Test): 0.0036\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Define base estimators\n",
        "estimators = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    ('knn', KNeighborsClassifier(n_neighbors=5, weights='distance')),\n",
        "    ('log_reg', LogisticRegression())\n",
        "]\n",
        "\n",
        "# Initialize the Stacking model with Logistic Regression as the meta-learner\n",
        "model_stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=5)\n",
        "\n",
        "# Evaluate the Stacking model using original data\n",
        "metrics_stacking_orig = evaluate_model(model_stacking, X_train_orig, X_test_orig, y_train_orig, y_test_orig)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Original Data with Stacking:\")\n",
        "for metric, value in metrics_stacking_orig.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qVRltBjBqp0"
      },
      "source": [
        "### Hyperparameter Stacking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epQhewQVBuCr",
        "outputId": "92f7f8be-5221-404d-93eb-8bb91abdeb40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
            "Best Parameters for Stacking Classifier: {'final_estimator__C': 10, 'knn__n_neighbors': 5, 'rf__max_depth': None}\n",
            "Evaluation Metrics on Original Data with Best Stacking Model:\n",
            "Accuracy (Train Set): 0.9627\n",
            "Accuracy (Test Set): 0.9196\n",
            "Precision (Test Set): 0.3391\n",
            "Recall (Test Set): 0.0054\n",
            "F1-Score (Test Set): 0.0106\n",
            "F2-Score (Test Set): 0.0067\n",
            "ROC AUC (Train Set): 0.9998\n",
            "ROC AUC (Test Set): 0.6848\n",
            "Recall (Cross-Validation Train): 0.0068\n",
            "Recall (Cross-Validation Test): 0.0040\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define base estimators\n",
        "estimators = [\n",
        "    ('rf', RandomForestClassifier(random_state=42)),\n",
        "    ('knn', KNeighborsClassifier()),\n",
        "    ('log_reg', LogisticRegression())\n",
        "]\n",
        "\n",
        "# Initialize Stacking Classifier with Logistic Regression as the meta-learner\n",
        "model_stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=5)\n",
        "\n",
        "# Define parameter grid for hyperparameter tuning\n",
        "param_grid_stacking = {\n",
        "    'final_estimator__C': [0.01, 0.1, 1, 10],\n",
        "    'rf__max_depth': [None, 10, 20, 30],\n",
        "    'knn__n_neighbors': [3, 5, 7, 9],\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV for hyperparameter tuning using the original training data\n",
        "grid_search_stacking = GridSearchCV(estimator=model_stacking, param_grid=param_grid_stacking, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
        "grid_search_stacking.fit(X_train_orig, y_train_orig)\n",
        "\n",
        "# Get the best model with the best parameters\n",
        "best_stacking_model = grid_search_stacking.best_estimator_\n",
        "print(\"Best Parameters for Stacking Classifier:\", grid_search_stacking.best_params_)\n",
        "\n",
        "# Evaluate the best model using the original test data\n",
        "metrics_stacking_orig = evaluate_model(best_stacking_model, X_train_orig, X_test_orig, y_train_orig, y_test_orig)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Original Data with Best Stacking Model:\")\n",
        "for metric, value in metrics_stacking_orig.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8cJcfiA9RiV"
      },
      "source": [
        "### 7a. Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFE9yOSQ9Zaw",
        "outputId": "1613c8e4-aaeb-47be-bfee-fb829cc75b5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Oversampled Data with Stacking:\n",
            "Accuracy (Train Set): 1.0000\n",
            "Accuracy (Test Set): 0.9443\n",
            "Precision (Test Set): 0.9817\n",
            "Recall (Test Set): 0.8489\n",
            "F1-Score (Test Set): 0.9104\n",
            "F2-Score (Test Set): 0.8725\n",
            "ROC AUC (Train Set): 1.0000\n",
            "ROC AUC (Test Set): 0.9658\n",
            "Recall (Cross-Validation Train): 0.8470\n",
            "Recall (Cross-Validation Test): 0.8297\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define base estimators\n",
        "estimators = [\n",
        "    ('decision_tree', DecisionTreeClassifier()),\n",
        "    ('random_forest', RandomForestClassifier())\n",
        "]\n",
        "\n",
        "# Define the Stacking model with Logistic Regression as the meta-learner\n",
        "model_stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "\n",
        "# Fit the model to the oversampled training data\n",
        "model_stacking.fit(X_train_over, y_train_over)\n",
        "\n",
        "# Evaluate the model\n",
        "metrics_stacking_over = evaluate_model(model_stacking, X_train_over, X_test_over, y_train_over, y_test_over)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Oversampled Data with Stacking:\")\n",
        "for metric, value in metrics_stacking_over.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLXn8tWa9Uqb"
      },
      "source": [
        "### 7b. Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rddxUpNQ9b4S",
        "outputId": "471b4fdf-c04d-4126-f5af-f91d86980eb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Undersampled Data with Stacking:\n",
            "Accuracy (Train Set): 1.0000\n",
            "Accuracy (Test Set): 0.6325\n",
            "Precision (Test Set): 0.6146\n",
            "Recall (Test Set): 0.4735\n",
            "F1-Score (Test Set): 0.5349\n",
            "F2-Score (Test Set): 0.4963\n",
            "ROC AUC (Train Set): 1.0000\n",
            "ROC AUC (Test Set): 0.6706\n",
            "Recall (Cross-Validation Train): 0.4724\n",
            "Recall (Cross-Validation Test): 0.4649\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define base estimators\n",
        "estimators = [\n",
        "    ('decision_tree', DecisionTreeClassifier()),\n",
        "    ('random_forest', RandomForestClassifier())\n",
        "]\n",
        "\n",
        "# Define the Stacking model\n",
        "model_stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "\n",
        "# Fit the model to the undersampled training data\n",
        "model_stacking.fit(X_train_under, y_train_under)\n",
        "\n",
        "# Evaluate the model\n",
        "metrics_stacking_under = evaluate_model(model_stacking, X_train_under, X_test_under, y_train_under, y_test_under)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Evaluation Metrics on Undersampled Data with Stacking:\")\n",
        "for metric, value in metrics_stacking_under.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yIjCVPAVgtS"
      },
      "source": [
        "# Tabel Hasil Pemodelan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkTD4TgZ0sIU"
      },
      "source": [
        "## Table 1. All Model (Data Biasa)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMd6f3PHLs1r"
      },
      "source": [
        "| Metric               | Logistic Regression | kNN    | Decision Tree | Random Forest | AdaBoost | XGBoost | Stacking |\n",
        "|----------------------|---------------------|--------|---------------|---------------|----------|---------|----------|\n",
        "| Accuracy (Train)     | 0.9194              | 1.0000 | 1.0000        | 1.0000        | 0.9194   | 0.9195  | 0.9612   |\n",
        "| Accuracy (Test)      | 0.9200              | 0.9146 | 0.8469        | 0.9200        | 0.9200   | 0.9200  | 0.9196   |\n",
        "| Precision (Test)     | 0.5000              | 0.1484 | 0.1121        | 1.0000        | 1.0000   | 0.5385  | 0.3299   |\n",
        "| Recall (Test)        | 0.0001              | 0.0142 | 0.1322        | 0.0001        | 0.0001   | 0.0010  | 0.0044   |\n",
        "| F1-Score (Test)      | 0.0003              | 0.0258 | 0.1213        | 0.0003        | 0.0003   | 0.0019  | 0.0087   |\n",
        "| F2-Score (Test)      | 0.0002              | 0.0173 | 0.1276        | 0.0002        | 0.0002   | 0.0012  | 0.0055   |\n",
        "| ROC AUC (Train)      | 0.6770              | 1.0000 | 1.0000        | 1.0000        | 0.6910   | 0.7726  | 0.9998   |\n",
        "| ROC AUC (Test)       | 0.6799              | 0.5435 | 0.5206        | 0.6544        | 0.6933   | 0.7109  | 0.6847   |\n",
        "| Recall (CV Train)    | 0.0002              | 0.0147 | 0.1260        | 0.0002        | 0.0002   | 0.0006  | 0.0066   |\n",
        "| Recall (CV Test)     | 0.0001              | 0.0148 | 0.1387        | 0.0000        | 0.0001   | 0.0025  | 0.0036   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYnzr9jmXCwk"
      },
      "source": [
        "**Semua model** pada data biasa memiliki recall dan F2-Score yang **rendah**, mengindikasikan banyak FN yang berpotensi meningkatkan risiko gagal bayar. Oleh karena itu, pendekatan ini kurang efektif untuk mencapai goal proyek"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZhuU8IL8qyv"
      },
      "source": [
        "## Table 2. All Model (Oversampling)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic9cEle8L9A5"
      },
      "source": [
        "| Metric               | Logistic Regression | kNN    | Decision Tree | Random Forest | AdaBoost | XGBoost | Stacking |\n",
        "|----------------------|---------------------|--------|---------------|---------------|----------|---------|----------|\n",
        "| Accuracy (Train)     | 0.6935              | 1.0000 | 1.0000        | 1.0000        | 0.8974   | 0.9408  | 1.0000   |\n",
        "| Accuracy (Test)      | 0.6922              | 0.7757 | 0.8469        | 0.9370        | 0.8967   | 0.9390  | 0.9443   |\n",
        "| Precision (Test)     | 0.5775              | 0.5996 | 0.1121        | 0.9996        | 0.9669   | 0.9985  | 0.9817   |\n",
        "| Recall (Test)        | 0.2894              | 0.9870 | 0.1322        | 0.8117        | 0.7150   | 0.8183  | 0.8489   |\n",
        "| F1-Score (Test)      | 0.3856              | 0.7460 | 0.1213        | 0.8959        | 0.8221   | 0.8995  | 0.9104   |\n",
        "| F2-Score (Test)      | 0.3215              | 0.8741 | 0.1276        | 0.8434        | 0.7543   | 0.8489  | 0.8725   |\n",
        "| ROC AUC (Train)      | 0.7071              | 1.0000 | 1.0000        | 1.0000        | 0.9214   | 0.9647  | 1.0000   |\n",
        "| ROC AUC (Test)       | 0.7042              | 0.9445 | 0.5206        | 0.9655        | 0.9199   | 0.9471  | 0.9658   |\n",
        "| Recall (CV Train)    | 0.2908              | 0.9755 | 0.1260        | 0.8076        | 0.7144   | 0.8205  | 0.8470   |\n",
        "| Recall (CV Test)     | 0.2874              | 0.8955 | 0.1387        | 0.7778        | 0.7168   | 0.8175  | 0.8297   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k-X5CVvXHW1"
      },
      "source": [
        "**Stacking** lalu diperingkat kedua **XGBoost** adalah model terbaik dalam pendekatan ini dengan F2-Score yang tinggi, menunjukkan keseimbangan yang baik antara deteksi nasabah berisiko dan inklusi finansial. Model ini memungkinkan deteksi yang akurat terhadap nasabah gagal bayar, yang sejalan dengan goal untuk mengurangi risiko kredit macet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd4WQVEN8zRw"
      },
      "source": [
        "## Table 3. All Model (Undersampling)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xONelQfFY1Av"
      },
      "source": [
        "| Metric                        | Logistic Regression | kNN    | Decision Tree | Random Forest | AdaBoost | XGBoost | Stacking |\n",
        "|-------------------------------|---------------------|--------|---------------|---------------|----------|---------|----------|\n",
        "| Accuracy (Train Set)          | 0.6405             | 1.0000 | 1.0000        | 1.0000        | 0.6455   | 0.7960  | 1.0000   |\n",
        "| Accuracy (Test Set)           | 0.6391             | 0.5556 | 0.5533        | 0.6364        | 0.6449   | 0.6431  | 0.6325   |\n",
        "| Precision (Test Set)          | 0.6157             | 0.5023 | 0.4996        | 0.6254        | 0.6266   | 0.6150  | 0.6146   |\n",
        "| Recall (Test Set)             | 0.5093             | 0.4721 | 0.5023        | 0.4622        | 0.5056   | 0.5361  | 0.4735   |\n",
        "| F1-Score (Test Set)           | 0.5575             | 0.4867 | 0.5009        | 0.5315        | 0.5596   | 0.5728  | 0.5349   |\n",
        "| F2-Score (Test Set)           | 0.5275             | 0.4779 | 0.5018        | 0.4876        | 0.5259   | 0.5502  | 0.4963   |\n",
        "| ROC AUC (Train Set)           | 0.6843             | 1.0000 | 1.0000        | 1.0000        | 0.6916   | 0.8808  | 1.0000   |\n",
        "| ROC AUC (Test Set)            | 0.6762             | 0.5640 | 0.5484        | 0.6717        | 0.6876   | 0.6898  | 0.6706   |\n",
        "| Recall (Cross-Validation Train)| 0.5005            | 0.4808 | 0.4945        | 0.4554        | 0.5118   | 0.5343  | 0.4724   |\n",
        "| Recall (Cross-Validation Test) | 0.5008            | 0.4737 | 0.5184        | 0.4522        | 0.5159   | 0.5348  | 0.4649   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGXhcdKUXd9g"
      },
      "source": [
        "**XGBoost** menunjukkan recall yang cukup baik (0.5361) dibandingkan data biasa, menurunkan FN namun menghasilkan lebih banyak FP karena lebih sering memprediksi defaulter. F2-Score (0.5553) menunjukkan peningkatan sensitivitas, tetapi tidak sebaik oversampling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMxVLM2D87ox"
      },
      "source": [
        "## Table 4. All Model (Hyperparameter Data Biasa)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9fjgJY6NE4S"
      },
      "source": [
        "\n",
        "\n",
        "| Metric               | Logistic Regression | kNN    | Decision Tree | Random Forest | AdaBoost | XGBoost | Stacking |\n",
        "|----------------------|---------------------|--------|---------------|---------------|----------|---------|----------|\n",
        "| Accuracy (Train)     | 0.9194              | 1.0000 | 0.9998        | 0.9998        | 0.9189   | 0.9251  | 0.9627   |\n",
        "| Accuracy (Test)      | 0.9200              | 0.9033 | 0.8535        | 0.9200        | 0.9190   | 0.9192  | 0.9196   |\n",
        "| Precision (Test)     | 0.5000              | 0.1213 | 0.1210        | 0.0000        | 0.3168   | 0.3590  | 0.3391   |\n",
        "| Recall (Test)        | 0.0001              | 0.0335 | 0.1327        | 0.0000        | 0.0114   | 0.0135  | 0.0054   |\n",
        "| F1-Score (Test)      | 0.0003              | 0.0525 | 0.1266        | 0.0000        | 0.0220   | 0.0260  | 0.0106   |\n",
        "| F2-Score (Test)      | 0.0002              | 0.0392 | 0.1302        | 0.0000        | 0.0141   | 0.0167  | 0.0067   |\n",
        "| ROC AUC (Train)      | 0.6776              | 1.0000 | 1.0000        | 1.0000        | 0.7329   | 0.9016  | 0.9998   |\n",
        "| ROC AUC (Test)       | 0.6805              | 0.5334 | 0.5242        | 0.6564        | 0.6969   | 0.6893  | 0.6848   |\n",
        "| Recall (CV Train)    | 0.0002              | 0.0386 | 0.1304        | 0.0003        | 0.0134   | 0.0138  | 0.0068   |\n",
        "| Recall (CV Test)     | 0.0001              | 0.0393 | 0.1340        | 0.0000        | 0.0242   | 0.0197  | 0.0040   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJimY8lhajNI"
      },
      "source": [
        "Setelah tuning, **semua model** pada data biasa memiliki nilai **recall** yang **sangat rendah**, membuat mereka kurang ideal untuk mendeteksi nasabah berisiko gagal bayar. Model ini tidak mencapai performa yang diinginkan dalam hal recall dan lebih baik dievaluasi ulang dengan pendekatan yang berbeda, seperti oversampling atau undersampling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWHTnMiv9Exh"
      },
      "source": [
        "## Table 5. Best Model of Undersampling (Before & After Hyperparameter)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb8LLi_YPHBi"
      },
      "source": [
        "| Metric                          | XGBoost Before Tuning | XGBoost After Tuning |\n",
        "|---------------------------------|-----------------------|-----------------------|\n",
        "| Accuracy (Train Set)            | 0.9408                | 0.7004                |\n",
        "| Accuracy (Test Set)             | 0.9390                | 0.6578                |\n",
        "| Precision (Test Set)            | 0.9985                | 0.6385                |\n",
        "| Recall (Test Set)               | 0.8183                | 0.5378                |\n",
        "| F1-Score (Test Set)             | 0.8995                | 0.5839                |\n",
        "| F2-Score (Test Set)             | 0.8489                | 0.5553                |\n",
        "| ROC AUC (Train Set)             | 0.9647                | 0.7697                |\n",
        "| ROC AUC (Test Set)              | 0.9471                | 0.7112                |\n",
        "| Recall (Cross-Validation Train) | 0.8205                | 0.5398                |\n",
        "| Recall (Cross-Validation Test)  | 0.8175                | 0.5412                |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IrAxpJrWInw"
      },
      "source": [
        "Berdasarkan goal utama proyek yaitu secara agresif mengurangi risiko gagal bayar dengan mendeteksi sebanyak mungkin nasabah berisiko, maka **model sebelum tuning** lebih sesuai karena memiliki recall dan F2-Score yang lebih tinggi, meskipun ada risiko overfitting. Model ini akan lebih sensitif terhadap nasabah berisiko, mengurangi jumlah defaulter yang tidak terdeteksi (FN), meskipun ada peningkatan risiko FP dan overfitting.<br>\n",
        "\n",
        "Namun, jika stabilitas model dan kemampuan generalisasi untuk data baru menjadi pertimbangan penting, terutama untuk implementasi jangka panjang, maka model sesudah tuning lebih direkomendasikan. Meskipun recall menurun, model ini lebih seimbang dan lebih cocok untuk kondisi data yang mungkin berubah di masa depan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFcR03p0h1pW"
      },
      "source": [
        "Pada data original dan Undersampling, hasil tuning pada model-model ini justru menurunkan performa utama yang dibutuhkan untuk mencapai tujuan proyek. Penurunan recall dan ROC AUC menunjukkan bahwa model menjadi kurang efektif dalam mendeteksi nasabah berisiko, yang dapat berakibat pada meningkatnya risiko kredit macet dan menurunnya inklusi finansial. **Model dengan parameter default dan menggunakan oversampling**, terutama pada **Stacking** dan XGBoost, memberikan hasil yang lebih baik untuk tujuan proyek, karena mereka mempertahankan nilai recall dan ROC AUC yang tinggi tanpa\n",
        "menyebabkan overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-rLcmV98_X5"
      },
      "source": [
        "## Table 6. The Best Model: Oversampling Without Tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ihIbERdvtzs"
      },
      "source": [
        "| Metric               | XGBoost | Stacking |\n",
        "|----------------------|---------|----------|\n",
        "| Accuracy (Train)     | 0.9408  | 1.0000   |\n",
        "| Accuracy (Test)      | 0.9390  | 0.9443   |\n",
        "| Precision (Test)     | 0.9985  | 0.9817   |\n",
        "| Recall (Test)        | 0.8183  | 0.8489   |\n",
        "| F1-Score (Test)      | 0.8995  | 0.9104   |\n",
        "| F2-Score (Test)      | 0.8489  | 0.8725   |\n",
        "| ROC AUC (Train)      | 0.9647  | 1.0000   |\n",
        "| ROC AUC (Test)       | 0.9471  | 0.9658   |\n",
        "| Recall (CV Train)    | 0.8205  | 0.8470   |\n",
        "| Recall (CV Test)     | 0.8175  | 0.8297   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kesimpulan:**\n",
        "\n",
        "1. **Modeling**: Implementasi menggunakan **XGBoost** dan **Stacking** untuk menangani data oversampling dengan algoritma yang lebih kompleks dari kelas.\n",
        "  \n",
        "2. **Model Evaluation**: **XGBoost** unggul dalam **ROC AUC** (0.9471) dan **Recall**, sesuai dengan tujuan proyek untuk mendeteksi risiko default. **Stacking** menunjukkan performa sedikit lebih baik pada beberapa metrik (seperti **F1-Score**), tetapi lebih kompleks dan memakan waktu.\n",
        "\n",
        "3. **Best Fit & Validasi**: **XGBoost** terbukti **best-fit** melalui cross-validation tanpa overfitting, menunjukkan stabilitas performa pada data tes.\n",
        "\n",
        "4. **Efisiensi**: Tanpa tuning, **XGBoost** mencapai performa yang sangat baik, memenuhi kebutuhan proyek tanpa meningkatkan beban komputasi.\n",
        "\n",
        "**Kesimpulan Akhir**: **XGBoost** dipilih karena memberikan keseimbangan terbaik antara performa, efisiensi, dan kesesuaian dengan tujuan proyek, menjadikannya pilihan optimal untuk mendeteksi risiko default."
      ],
      "metadata": {
        "id": "3vYcsCck9gpB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jadi berikut ini merupakan Model Terbaik: XGBoost Oversampled dengan Best Parameter (Setelah Hyperparameter)"
      ],
      "metadata": {
        "id": "cmsRNiqx6nVn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Table: XGBoost Metrics Before and After Hyperparameter Tuning (Oversampling)\n",
        "\n",
        "| Metric                       | Before Tuning | After Tuning |\n",
        "|------------------------------|---------------|--------------|\n",
        "| Accuracy (Train Set)         | 0.9408        | 0.9460       |\n",
        "| Accuracy (Test Set)          | 0.9390        | 0.9397       |\n",
        "| Precision (Test Set)         | 0.9985        | 0.9966       |\n",
        "| Recall (Test Set)            | 0.8183        | 0.8220       |\n",
        "| F1-Score (Test Set)          | 0.8995        | 0.9009       |\n",
        "| F2-Score (Test Set)          | 0.8489        | 0.8519       |\n",
        "| ROC AUC (Train Set)          | 0.9647        | 0.9861       |\n",
        "| ROC AUC (Test Set)           | 0.9471        | 0.9470       |\n",
        "| Recall (Cross-Validation Train) | 0.8205     | 0.8239       |\n",
        "| Recall (Cross-Validation Test)  | 0.8175     | 0.8208       |\n"
      ],
      "metadata": {
        "id": "KUUxeCP4-P62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analisa Model Terbaik: XGBoost Oversampled dengan Best Parameter\n",
        "\n",
        "Berdasarkan tabel performa model sebelum dan setelah *hyperparameter tuning*, XGBoost dengan data oversampled menunjukkan peningkatan performa yang signifikan setelah tuning, menjadikannya model terbaik untuk prediksi risiko default:\n",
        "\n",
        "1. **Peningkatan Akurasi**: Akurasi pada data *train* meningkat dari **94.08%** menjadi **94.60%**, menunjukkan model semakin mampu mempelajari pola data dengan baik tanpa *overfitting*. Akurasi pada data *test* tetap stabil di angka **93.97%**, menunjukkan kemampuan generalisasi yang baik.\n",
        "\n",
        "2. **Precision yang Stabil**: Precision sedikit menurun dari **99.85%** menjadi **99.66%**, tetapi tetap sangat tinggi. Hal ini menunjukkan model tetap efisien dalam meminimalkan *false positives*.\n",
        "\n",
        "3. **Peningkatan Recall**: Recall meningkat dari **81.83%** menjadi **82.20%**, yang sangat penting dalam konteks prediksi risiko default. Ini berarti model berhasil menangkap lebih banyak kasus default.\n",
        "\n",
        "4. **F1-Score dan F2-Score yang Meningkat**: F1-Score naik dari **89.95%** menjadi **90.09%**, menunjukkan keseimbangan yang lebih baik antara precision dan recall. F2-Score, yang lebih menekankan recall, juga meningkat dari **84.89%** menjadi **85.19%**, mendukung tujuan utama meminimalkan risiko gagal bayar.\n",
        "\n",
        "5. **ROC AUC yang Sangat Tinggi**: ROC AUC pada data *train* meningkat dari **96.47%** menjadi **98.61%**, mengindikasikan kemampuan model untuk membedakan antara nasabah default dan non-default semakin baik. ROC AUC pada data *test* tetap sangat tinggi di angka **94.70%**, menegaskan kualitas prediksi model.\n",
        "\n",
        "6. **Stabilitas dalam Cross-Validation**: Recall pada *cross-validation* meningkat pada data *train* (dari **82.05%** ke **82.39%**) dan pada data *test* (dari **81.75%** ke **82.08%**), menunjukkan model yang lebih konsisten pada berbagai lipatan data.\n",
        "\n",
        "### Kesimpulan:\n",
        "XGBoost setelah *hyperparameter tuning* dengan data oversampled menjadi pilihan terbaik karena menunjukkan peningkatan yang signifikan dalam metrik utama, terutama recall, F1-score, dan ROC AUC. Model ini sangat cocok untuk memprediksi risiko default, memastikan jumlah kasus default yang lebih tinggi dapat diidentifikasi tanpa mengorbankan presisi."
      ],
      "metadata": {
        "id": "c3Nc0ysR-wc5"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}